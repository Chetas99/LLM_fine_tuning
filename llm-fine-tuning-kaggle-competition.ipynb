{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 📝 LLM Classification Fine-tuning (RoBERTa Transformer)\n\nThis notebook demonstrates fine-tuning of a RoBERTa-based transformer model to classify preferred responses between pairs of chatbot-generated interactions. It's part of the [LLM Classification Fine-tuning Kaggle competition](https://www.kaggle.com/competitions/llm-classification-finetuning).\n\n**Author**: Chetas Srinivas  \n**Date**: March 2025\n","metadata":{}},{"cell_type":"markdown","source":"## ⚙️ Setup & Installation\n\nInstall all necessary dependencies including Hugging Face Transformers, datasets, WandB, and other key libraries.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    Trainer,\n    TrainingArguments\n)\nimport torch\nimport numpy as np\nimport wandb\n\n# Initialize wandb (it will prompt for API key)\nwandb.login()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📂 Data Loading and Exploration\n\nLoading and exploring datasets provided by the competition, which include training and testing data.\n","metadata":{}},{"cell_type":"code","source":"# Load data\ntrain_df = pd.read_csv('train.csv')\ntest_df = pd.read_csv('test.csv')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🛠️ Data Preprocessing\n\nPrepare textual data for classification tasks by combining prompt and responses. Convert multi-class labels to a single integer class for classification.\n","metadata":{}},{"cell_type":"code","source":"# Prepare data function\ndef prepare_data(df):\n    texts = df['prompt'] + ' [SEP] ' + df['response_a'] + ' [SEP] ' + df['response_b']\n    labels = df[['winner_model_a', 'winner_model_b', 'winner_tie']].values.argmax(axis=1)\n    return texts.tolist(), labels\n\ntrain_texts, train_labels = prepare_data(train_df)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🧪 Train-Validation Split\n\nSplitting the data into training and validation sets to evaluate model performance and avoid overfitting.\n","metadata":{}},{"cell_type":"code","source":"# Train-validation split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_texts, train_labels, test_size=0.1, random_state=42\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🤖 Model and Tokenizer Setup\n\nUsing a pre-trained RoBERTa model and tokenizer from Hugging Face for sequence classification.\n","metadata":{}},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained('roberta-base')\nmodel = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=3)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📝 Tokenization\n\nConvert textual data into tokenized sequences suitable for transformer input.\n","metadata":{}},{"cell_type":"code","source":"# Tokenize data with optimized token length\ndef tokenize(batch):\n    return tokenizer(batch, padding=True, truncation=True, max_length=256)\n\ntrain_encodings = tokenize(train_texts)\nval_encodings = tokenize(val_texts)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📦 PyTorch Dataset Class\n\nCustom dataset class to handle tokenized data efficiently during training and evaluation.\n","metadata":{}},{"cell_type":"code","source":"# Dataset class\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = Dataset(train_encodings, train_labels)\nval_dataset = Dataset(val_encodings, val_labels)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🚀 Model Training\n\nTraining the RoBERTa model with Hugging Face's Trainer API. The training process is logged and visualized using **Weights & Biases (wandb)**.\n","metadata":{}},{"cell_type":"code","source":"# Training arguments (wandb integration)\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model='accuracy',\n    report_to=\"wandb\",  # Enables wandb logging\n    run_name=\"llm_classification_finetune\",  # Name your wandb run clearly\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📊 Model Evaluation and Predictions\n\nEvaluating the trained model on test data to generate predictions for the competition submission.\n","metadata":{}},{"cell_type":"code","source":"# Metrics\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    return {'accuracy': (preds == p.label_ids).mean()}\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> **⚠️ Note:**  \n> Training was initially executed on Google Colab, and outputs have been preserved here for quick reference and demonstration purposes.\n","metadata":{}},{"cell_type":"code","source":"# Start training\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare test data for predictions\ntest_texts = test_df['prompt'] + ' [SEP] ' + test_df['response_a'] + ' [SEP] ' + test_df['response_b']\ntest_encodings = tokenize(test_texts.tolist())\ntest_dataset = Dataset(test_encodings, [0]*len(test_df))\n\n# Predictions\npredictions = trainer.predict(test_dataset)\npreds = np.argmax(predictions.predictions, axis=1)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ✅ Submission File\n\nGenerate the final submission file (`submission.csv`) in the format required by Kaggle.\n","metadata":{}},{"cell_type":"code","source":"# Submission\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'winner_model_a': (preds == 0).astype(int),\n    'winner_model_b': (preds == 1).astype(int),\n    'winner_tie': (preds == 2).astype(int)\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"iwscihwsdZjm","outputId":"1084e025-bd48-4f84-c05d-2cb51fbe91e1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🎯 Conclusion & Future Improvements\n\n**Key insights from the current run**:\n- Initial accuracy was ~37%. Indicates room for improvement through more extensive hyperparameter tuning and longer training.\n\n**Possible future improvements**:\n- Use more advanced models (e.g., DeBERTa).\n- Increase epochs and fine-tune hyperparameters.\n- Implement hyperparameter optimization techniques.\n\n**Explore further**:\n- [wandb Dashboard](your wandb URL)\n- [GitHub Repository](your GitHub link)\n","metadata":{}}]}